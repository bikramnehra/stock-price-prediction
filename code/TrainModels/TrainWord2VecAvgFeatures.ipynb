{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.classification import SVMWithSGD\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.sql import SQLContext, Row\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "def mapLabel(st):\n",
    "    if st == 'up':\n",
    "        return 0.0\n",
    "    elif st == 'do':\n",
    "        return 1.0\n",
    "    elif st == 'st':\n",
    "        return 2.0\n",
    "    else:\n",
    "        return 3.0\n",
    "        \n",
    "\n",
    "def mapLabels(d):\n",
    "    label = d['Dir']\n",
    "    Features = d['Child'][0]['WordVec'].toArray().tolist()\n",
    "    for vec in map(lambda l:l['WordVec'],d['Child'][1:]):\n",
    "        Features = Features + vec.toArray().tolist()\n",
    "    \n",
    "    return (mapLabel(label),Features)\n",
    "\n",
    "rawData = sc.pickleFile('./FeatureVector').\\\n",
    "            filter(lambda l:l['Symbol']!='SNP500').\\\n",
    "            map(mapLabels).\\\n",
    "            sample(False,0.01).\\\n",
    "            filter(lambda l:len(l[1])==100*30).\\\n",
    "            map(lambda l:(l[0],Vectors.dense(l[1]))).cache()\n",
    "            \n",
    "#sample(False,0.01).\\\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  2.0|[0.0,0.0,0.0,0.0,...|\n",
      "|  0.0|[0.02716893302805...|\n",
      "|  2.0|[0.00893773724359...|\n",
      "|  2.0|[0.00353481636151...|\n",
      "|  1.0|[0.02290219965803...|\n",
      "|  2.0|[0.01039333985355...|\n",
      "|  2.0|[-0.0131412900936...|\n",
      "|  0.0|[0.03101800782838...|\n",
      "|  2.0|[-0.0148460686700...|\n",
      "|  0.0|[0.0,0.0,0.0,0.0,...|\n",
      "|  2.0|[0.01144807768629...|\n",
      "|  1.0|[0.05400354475929...|\n",
      "|  0.0|[0.00413107639440...|\n",
      "|  0.0|[-0.0334426911193...|\n",
      "|  2.0|[0.00154690247466...|\n",
      "|  0.0|[0.0,0.0,0.0,0.0,...|\n",
      "|  0.0|[0.00749564381784...|\n",
      "|  2.0|[-0.0270764063113...|\n",
      "|  2.0|[-0.0085780138738...|\n",
      "|  0.0|[0.0,0.0,0.0,0.0,...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = sqlContext.createDataFrame(rawData,[\"label\", \"features\"]).cache()\n",
    "df.show()\n",
    "mlp = MultilayerPerceptronClassifier(maxIter=100, layers=[100*30, 1*30, 3], seed=11)\n",
    "model = mlp.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#testDf = sqlContext.createDataFrame(rawData.map(lambda l:[l[1]]),[\"features\"]).cache()\n",
    "#testDf.show()\n",
    "#model.transform(testDf).show()\n",
    "test = sc.pickleFile('./FeatureVectorTest/').\\\n",
    "        filter(lambda l:l['Symbol']!='SNP500').\\\n",
    "        cache()\n",
    "\n",
    "testData = test.\\\n",
    "            map(mapLabels).\\\n",
    "            filter(lambda l:len(l[1])==100*30).\\\n",
    "            map(lambda l:(l[0],Vectors.dense(l[1]))).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, 1.0)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDf = sqlContext.createDataFrame(testData.map(lambda l:[l[1]]),[\"features\"]).cache()\n",
    "#testDf.show()\n",
    "model.transform(testDf).rdd.\\\n",
    "    zip(testData).\\\n",
    "    map(lambda (a,b):(a.prediction,b[0])).\\\n",
    "    take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([datetime.datetime(2015, 4, 7, 0, 0),\n",
       "   datetime.datetime(2015, 4, 6, 0, 0),\n",
       "   datetime.datetime(2015, 4, 2, 0, 0),\n",
       "   datetime.datetime(2015, 4, 1, 0, 0),\n",
       "   datetime.datetime(2015, 3, 31, 0, 0),\n",
       "   datetime.datetime(2015, 3, 30, 0, 0),\n",
       "   datetime.datetime(2015, 3, 27, 0, 0),\n",
       "   datetime.datetime(2015, 3, 26, 0, 0),\n",
       "   datetime.datetime(2015, 3, 25, 0, 0),\n",
       "   datetime.datetime(2015, 3, 24, 0, 0),\n",
       "   datetime.datetime(2015, 3, 23, 0, 0),\n",
       "   datetime.datetime(2015, 3, 20, 0, 0),\n",
       "   datetime.datetime(2015, 3, 19, 0, 0),\n",
       "   datetime.datetime(2015, 3, 18, 0, 0),\n",
       "   datetime.datetime(2015, 3, 17, 0, 0),\n",
       "   datetime.datetime(2015, 3, 16, 0, 0),\n",
       "   datetime.datetime(2015, 3, 13, 0, 0),\n",
       "   datetime.datetime(2015, 3, 12, 0, 0),\n",
       "   datetime.datetime(2015, 3, 11, 0, 0),\n",
       "   datetime.datetime(2015, 3, 10, 0, 0),\n",
       "   datetime.datetime(2015, 3, 9, 0, 0),\n",
       "   datetime.datetime(2015, 3, 6, 0, 0),\n",
       "   datetime.datetime(2015, 3, 5, 0, 0),\n",
       "   datetime.datetime(2015, 3, 3, 0, 0),\n",
       "   datetime.datetime(2015, 3, 2, 0, 0),\n",
       "   datetime.datetime(2015, 2, 27, 0, 0),\n",
       "   datetime.datetime(2015, 2, 26, 0, 0),\n",
       "   datetime.datetime(2015, 2, 25, 0, 0),\n",
       "   datetime.datetime(2015, 2, 24, 0, 0)],\n",
       "  29)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.map(lambda l:(map(lambda l:l['Date'],l['Child']),len(l['Child']))).take(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
